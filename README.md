# Game-AI-Toolkit

Here we will keep track of the Game AI Development Toolkit, including programming, animation, effects, modeling, audio, music and more.

## Contents

| Source                                                             | Description                                                                                      | Game Engine | Type   |
| :----------------------------------------------------------------- | :----------------------------------------------------------------------------------------------- | :---------: | ------ |
| [AICommand](https://github.com/keijiro/AICommand)                     | ChatGPT integration with Unity Editor                                                            |    Unity    |        |
| [AI Shader](https://github.com/keijiro/AIShader)                      | ChatGPT-powered shader generator for Unity                                                       |    Unity    |        |
| [Stable Diffusion](https://github.com/CompVis/stable-diffusion)       | A latent text-to-image diffusion model.                                                          |            | Image  |
| [ControlNet](https://github.com/lllyasviel/ControlNet)                | ControlNet is a neural network structure to control diffusion models by adding extra conditions. |            | Image  |
| [Blender-ControlNet](https://github.com/coolzilj/Blender-ControlNet)  | Using ControlNet right in Blender.                                                               |            | Image  |
| [CodeGeeX](https://github.com/THUDM/CodeGeeX)                         | An Open Multilingual Code Generation Model.                                                      |            | Code   |
| [ArchiSound](https://github.com/archinetai/audio-diffusion-pytorch)   | Audio generation using diffusion models, in PyTorch.                                             |            | Audio  |
| [Make-An-Audio](https://text-to-audio.github.io/)                     | Text-To-Audio Generation with Prompt-Enhanced Diffusion Models.                                  |            | Audio  |
| [AudioLDM](https://audioldm.github.io/)                               | Text-to-Audio Generation with Latent Diffusion Models.                                           |            | Audio  |
| [MusicLM](https://google-research.github.io/seanet/musiclm/examples/) | Generating Music From Text.                                                                      |            | Music  |
| [VALL-E](https://valle-demo.github.io/)                               | Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers.                          |            | Speech |
| [VALL-E X](https://vallex-demo.github.io/)                            | Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec Language Modeling        |            | Speech |
